{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing the preprocessed data\n",
    "tot_data = pd.read_csv(\"final_label_encoding.csv\")\n",
    "train_data=tot_data.iloc[0:18359]\n",
    "test_data=tot_data.iloc[18359:]\n",
    "ids=test_data['enrollee_id']\n",
    "target=train_data['target']\n",
    "train_data.drop('target',axis=1,inplace=True)\n",
    "test_data.drop('target',axis=1,inplace=True)\n",
    "train_data.drop('enrollee_id',axis=1,inplace=True)\n",
    "test_data.drop('enrollee_id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Normalizing the training hours column\n",
    "\n",
    "x = train_data['training_hours'].reshape(-1, 1)\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "training_hours_scaled = x_scaled\n",
    "del(train_data['training_hours'])\n",
    "train_data['training_hours'] = training_hours_scaled\n",
    "\n",
    "x = test_data['training_hours'].reshape(-1, 1)\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "training_hours_scaled = x_scaled\n",
    "del(test_data['training_hours'])\n",
    "test_data['training_hours'] = training_hours_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Placeholders for input, target, loss penalty\n",
    "\n",
    "inp = tf.placeholder(shape=(None,1,16),dtype=tf.float32)\n",
    "tar = tf.placeholder(shape=(None),dtype=tf.float32)\n",
    "lo = tf.placeholder(shape=(None),dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Defining the weight and bias variables\n",
    "\n",
    "weight_1 = tf.Variable(tf.random_normal([64,30],mean=0,stddev=1))\n",
    "weight_2 = tf.Variable(tf.random_normal([30,10],mean=0,stddev=1))\n",
    "weight_3 = tf.Variable(tf.random_normal([10,1],mean=0,stddev=1))\n",
    "bias_1 = tf.Variable(tf.random_normal([30],mean=0,stddev=1))\n",
    "bias_2 = tf.Variable(tf.random_normal([10],mean=0,stddev=1))\n",
    "bias_3 = tf.Variable(tf.random_normal([1],mean=0,stddev=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#LSTM layer with h(t) = 64\n",
    "\n",
    "lstm = keras.layers.LSTM(64,input_shape=[None,1,16])(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dense layer with 30 neurons\n",
    "\n",
    "layer_1 =tf.nn.relu(tf.add(tf.matmul(lstm,weight_1),bias_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dropout layer for regularization\n",
    "\n",
    "dropout1 = keras.layers.Dropout(0.2)(layer_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dense layer with 10 neurons\n",
    "\n",
    "layer_2 = tf.nn.relu(tf.add(tf.matmul(dropout1,weight_2),bias_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dropout2 = keras.layers.Dropout(0.2)(layer_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dense layer with 1 neuron\n",
    "\n",
    "layer_3 = tf.add(tf.matmul(dropout2,weight_3),bias_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sigmoid layer for finding the AUC after every epoch\n",
    "\n",
    "sig_layer_3 = tf.nn.sigmoid(layer_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Binary cross entropy loss with L2 regularization\n",
    "\n",
    "los = (tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=layer_3,labels=tar)))+ (0.005*tf.nn.l2_loss(weight_1)) + (0.005*tf.nn.l2_loss(weight_2)) + (0.005*tf.nn.l2_loss(weight_3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Adam optimizer with default learning rate\n",
    "\n",
    "opt = tf.train.AdamOptimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Optimizing loss with additional penalty for loss with minor class 1\n",
    "\n",
    "model = opt.minimize(lo * los)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initializing the variables\n",
    "\n",
    "init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating the tf session\n",
    "\n",
    "ses = tf.InteractiveSession()\n",
    "ses.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reshaping training data to 3-d to fit LSTM input\n",
    "\n",
    "train_data = np.array(train_data)\n",
    "train_data = train_data.reshape([18359,1,16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reshaping the test data for LSTM input\n",
    "\n",
    "test_data = np.array(test_data)\n",
    "test_data = test_data.reshape([15021,1,16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.681664352568\n",
      "\n",
      "\n",
      "0.681906925345\n",
      "\n",
      "\n",
      "0.68191498695\n",
      "\n",
      "\n",
      "0.682047453478\n",
      "\n",
      "\n",
      "0.682016513997\n",
      "\n",
      "\n",
      "0.68198846013\n",
      "\n",
      "\n",
      "0.682007572474\n",
      "\n",
      "\n",
      "0.682031537308\n",
      "\n",
      "\n",
      "0.681996948754\n",
      "\n",
      "\n",
      "0.682094749087\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using online learning and with loss multipled by 200 when the data point is with label 1 and then pring the AUC after every epoch\n",
    "for epoch in range(0,50):\n",
    "    for i in range(0,(len(train_data))):\n",
    "        \n",
    "        a = train_data[i].reshape([1,1,16])\n",
    "        if(target[i] == 0):\n",
    "            c = 1.0\n",
    "        else:\n",
    "            c = 200.0\n",
    "\n",
    "        ses.run(model,feed_dict={inp:a,tar:target[i],lo:c})\n",
    "        \n",
    "    result = ses.run([sig_layer_3],feed_dict={inp:train_data})\n",
    "    result = result[0]\n",
    "    result = np.array(result)\n",
    "    result = result.reshape([18359,1])\n",
    "    print(roc_auc_score(y_true=target,y_score=result))    \n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Predicting on test data and saving to file\n",
    "\n",
    "predictions = ses.run([sig_layer_3],feed_dict={inp:test_data})\n",
    "predictions=predictions[0]\n",
    "predictions=predictions.reshape([15021])\n",
    "\n",
    "sub=pd.DataFrame({'enrollee_id':ids,'target':predictions})\n",
    "sub.to_csv(\"predictions_lstm.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
